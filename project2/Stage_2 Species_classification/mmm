3c3
< from torch.utils.data import DataLoader
---
> from torch.utils.data import  DataLoader
5c5
< from Species_Network import *
---
> from Classes_Network import *
16,17c16,17
< TRAIN_ANNO = 'Species_train_annotation.csv'
< VAL_ANNO = 'Species_val_annotation.csv'
---
> TRAIN_ANNO = 'Classes_train_annotation.csv'
> VAL_ANNO = 'Classes_val_annotation.csv'
19d18
< SPECIES = ['rabbits', 'rats', 'chickens']
44c43
<         label_species = int(self.file_info.iloc[idx]['species'])
---
>         label_class = int(self.file_info.iloc[idx]['classes'])
46c45
<         sample = {'image': image, 'species': label_species}
---
>         sample = {'image': image, 'classes': label_class}
78c77
<     print(idx, sample['image'].shape, SPECIES[sample['species']])
---
>     print(idx, sample['image'].shape, CLASSES[sample['classes']])
84c83
< def train_model(model, criterion, optimizer, num_epochs=50, lam=0.1):
---
> def train_model(model, criterion, optimizer, num_epochs=50, lam=1.0):
86c85
<     Accuracy_list_species = {'train': [], 'val': []}
---
>     Accuracy_list_classes = {'train': [], 'val': []}
103c102
<             corrects_species = 0
---
>             corrects_classes = 0
108c107
<                 labels_species = data['species'].to(device)
---
>                 labels_classes = data['classes'].to(device)
112,113c111
<                     x_species = model(inputs)
<                     x_species = x_species.view(-1,3)
---
>                     x_classes = model(inputs)
115c113,115
<                     _, preds_species = torch.max(x_species, 1)
---
>                     x_classes = x_classes.view(-1, 2)
> 
>                     _, preds_classes = torch.max(x_classes, 1)
120c120
<                     loss = criterion(x_species, labels_species) + lam * reg
---
>                     loss = criterion(x_classes, labels_classes) + lam * reg
128c128
<                 corrects_species += torch.sum(preds_species == labels_species)
---
>                 corrects_classes += torch.sum(preds_classes == labels_classes)
133,134c133,134
<             epoch_acc_species = corrects_species.double() / len(data_loaders[phase].dataset)
<             epoch_acc = epoch_acc_species
---
>             epoch_acc_classes = corrects_classes.double() / len(data_loaders[phase].dataset)
>             epoch_acc = epoch_acc_classes
136,137c136,137
<             Accuracy_list_species[phase].append(100 * epoch_acc_species)
<             print('{} Loss: {:.4f}  Acc_species: {:.2%}'.format(phase, epoch_loss,epoch_acc_species))
---
>             Accuracy_list_classes[phase].append(100 * epoch_acc_classes)
>             print('{} Loss: {:.4f}  Acc_classes: {:.2%}'.format(phase, epoch_loss,epoch_acc_classes))
141c141
<                 best_acc = epoch_acc_species
---
>                 best_acc = epoch_acc_classes
143c143
<                 print('Best val species Acc: {:.2%}'.format(best_acc))
---
>                 print('Best val classes Acc: {:.2%}'.format(best_acc))
147,148c147,148
<     print('Best val species Acc: {:.2%}'.format(best_acc))
<     return model, Loss_list,Accuracy_list_species
---
>     print('Best val classes Acc: {:.2%}'.format(best_acc))
>     return model, Loss_list,Accuracy_list_classes
163c163
<             for lam in [0,0.1,1.0]:
---
>             for lam in [0,0.1,10]:
165c165
<                 model, Loss_list, Accuracy_list_species = train_model(network, criterion, optimizer, num_epochs=20, lam=lam)
---
>                 model, Loss_list, Accuracy_list_classes = train_model(network, criterion, optimizer, num_epochs=20, lam=lam)
168,169c168,169
<                 y5 = Accuracy_list_species["train"]
<                 y6 = Accuracy_list_species["val"]
---
>                 y5 = Accuracy_list_classes["train"]
>                 y6 = Accuracy_list_classes["val"]
173,175c173,175
<                 plt.title('train and val Species acc vs. epoches')
<                 plt.ylabel('Species accuracy')
<                 plt.savefig("train and val Species acc vs epoches.jpg" + "Net_" + network_class + "_" + method + "_lr_" + str(lr) + "_lam_" + str(lam) + ".jpg")
---
>                 plt.title('train and val Classes_acc vs. epoches')
>                 plt.ylabel('Classes_accuracy')
>                 plt.savefig("train and val Classes_acc vs epoches" + "Net_" + network_class + "_" + method + "_lr_" + str(lr) + "_lam_" + str(lam) + ".jpg")
178c178
< ######################################## Visualization ##################################
---
> ############################################ Visualization ###############################################
184c184
<             labels_species = data['species'].to(device)
---
>             labels_classes = data['classes'].to(device)
186,188c186,188
<             x_species = model(inputs.to(device))
<             x_species = x_species.view(-1,3)
<             _, preds_species = torch.max(x_species, 1)
---
>             x_classes = model(inputs.to(device))
>             x_classes=x_classes.view( -1,2)
>             _, preds_classes = torch.max(x_classes, 1)
192c192
<             plt.title('predicted species: {}\n ground-truth species:{}'.format(SPECIES[preds_species],SPECIES[labels_species]))
---
>             plt.title('predicted classes: {}\n ground-truth classes:{}'.format(CLASSES[preds_classes],CLASSES[labels_classes]))
